- cvpo
	- be able to re-instantiate objects if they don't exist
	- be able to hash an MRTG a type/CVPO graph from both the compiler and identity perspective
	- the 'type' interning system should handle both CVPO and Type now
		- the act of walking types and CVPO should create the CVPOs as we go
			- need an object to manage this - we should be able to delete these when done?
		- when we duplicate the type object we'll produce a copy of the CVPO
			- we need to be able to produce the actual objects
- fully internalized types shouldn't be able to have an unstable identity at all
	- NamedModuleMember should identity hash the same way regardless anyways
	- we should force these Globals to resolve to something specific at resolution time
- Class/HeldClass classMembers could still have forwards. These are PyObjects and need to
	- be converted to Constants
- all Forward defined types need to expose as much of their internals as are known
	- not bytecounts - this should be explicitly disallowed
	- expose code to allow us to get the _first_ forward that defined a given class
- dotted globals?
	- if we do this, how do we resolve the dotted global value?
		- this is different for identity hashing than it is for serialization?
		- what were we doing in the existing system? This is very squirrely and difficult.
- fix the way we walk things in MRTG - should be unified so that we actually can see CVPOs
- ensure that TypeFunction works as intended now. Some of the weird issues should be resolved now
- fix the ModuleRepresentation stuff
- redocument everything
- finish serialization
	- should be able to serialize forward defined types
	- ensure we are not leaking PyObjSnapshot values
		- really PyObjSnapshot is the wrong name - i think it's more like 'TypeVisiblePyObj'
			which reflects the reality that some objects are visible to the typing system and some
			are not
	- can we get rid of the whole serialize-mrtg thing? at this point, memos should just work right?
		- this might leak which would be a problem
		- should CVPOs be shared_ptr? we can still create cycles in them
- fill out a full CVPO model:
	- classes
	- tuples
	- lists and other py datastructures
		- hash their original contents. they are not supposed to change
- function objects
	- default arguments need to be part of the instance closure if they have state?
- build a formal model for module objects and their contents
	- the only reassignment we should allow is for a module member to go from unresolved to resolved
	- nothing should change after import
	- this would let us detect module changes
	- we could serialize/deserialize without hitting the GIL
	- as part of this, move more of the serialization logic to C++ which would be faster
- ensure that we don't try to MRTG something that's a forward defined type
- fix the compiler to deal with the new globals thing now that we have it well defined
- figure out how to properly internalize python classes
	- the PyObjSnapshot thing needs to actually work
	- we need to make sure we can actually destroy these if we're not going to keep them
- get rid of PyObject throughout Function
	- should be like a FunctionGlobal
- Value should be holding a PyObjSnapshot, not an instance
- We're using the TP compiler hash in the compiler, which makes sense. Need to ensure that
	the CVOV obyes the same rules for dotted accesses that the original compiler does.
- We need to ensure that Globals retain their source information if its available
	- this means that they need to allow themselves to be constants
	- the whole 'globalsRaw' thing is trying to do this but its a crappy way of doing it
- take a look at object identity
	- we could keep a reverse lookup from all alive python objects to the original instance
		for things like lists/classes/etc


strategy:
	* fully fleshed out CVPO - infrastructure to help us manage all of this:
		* CVPO is really 'PyObjSnapshot' and represents a frozen graph of python objects
		* CVPO has an 'owner' which manages its lifetime.
			* there's an 'internalized' owner which represents CVPO that's owned by the core and that has been internalized by hash
			* these are leaked
		* CVPO models instances and Types all the way out
			* that is, a 'Type' is actually modeled with its pieces, which also have CVPO
				* the 'Type' and 'mPyObject' are pointers to the real thing
			* when you cross into a CVPO on another 'owner' then you can stop
			* instances are the same way, including classes, etc.
		* we replicate the MRTG hashing functionality on CVPO so that you can hash the items in a CVPO
			* you're not forced to internalize if you do this
	* when we freeze a Forward, we walk it to make a CVPO graph and hash it.
		* we then internalize the new part of the graph
		* then we walk back over the original objects and mark them as resolving to the new ones
		* then we autoresolve to update forwards that point to Cells and Modules
	* serialization
		* when we serialize a forward type, we just do it normally
		* but when we serialize a resolved type we serialize its CVPO graph
			* then when we deserialize it, we can deserialize the graph and then internalize it if we want to
			* this lets us gracefully handle the 'leak' case




question: how should we handle regular python classes defined in forwards?
* they will trigger MutuallyRecursiveTypeGroup and identityHash, which should be fine.
* we've said that Forwards shouldn't participate in MRTG.
	* This means we need to get a representation of the object that is completely external to 'forwards'
	* we won't allow monkey patching.
* I think we need to actually build the formal graph in CVPO, and this should proceed with standard
interning rules. This will allow us to completely remove the 'Forwards' from the object.
	* when a forward gets defined and pointed at a python object, we'll allow a walk inside
		* the question 'typeLooksResolvable' will be valid to ask of a Class that has forwards in it
			* if we ask 'isForwardDefined' we'll have to walk in and see if it references any forwards
		* this walk can't be cached until we make the model of the python object because the object is mutable
			* this could be slow but at least it's simple
* if you think about it what we really have is a graph of regular mutable python objects, of which
	forward defined types are just a special case. Periodically we walk this graph and check if
	we can do a forward resolution at which point we make a formal model
* to do this correctly we need two things:
	* a full model of python objects including Function and Class, PyList, PyTuple, etc.
	* a way of associating the model to a python instance
		* this association should be the one we use for MRTG of python instances that are interned - their shadows
			should be what we see and talk about, not the instances themselves.
		* the compiler should be using this, not the original objects
	* every CVPO should have a 'canonical' instance
		* every PyObj should have a mapping to the CVPO that represents it if its been forward resolved
	* you can ask if a python object isForwardDefined
		* function instances can be forward defined as well
	* if you choose to resolve (or we autoresolve, or a TypeFunction forces resolution) then we build the CVPO mapping
		* then CVPO can completely replace TOPO



def f(x):
	class C(Class):
		def g(self):
			return x

f(1) vs f(2)

what kind of global should 'x' be?
- we could leave it a GlobalInCell but it's really not - its a constant and shouldn't be allowed to change
	- part of the resolution process needs to get rid of the 'cellness' of this
	- fully resolved functions should only have constants, NamedModuleMember instances, and Unbound


def f(x):
	@Entrypoint
	def g():
		return x
	return g

in this case, 'x' is held in the function's closure, so it's not really 'typelike'


how should this work:
* we build a graph of unresolved forward types
	* these can see each other through cells, module members, and TypeFunction calls that yield Forwards.
* we trigger 'forward resolution'
* we build a complete model of all the python objects and types that are visible to the graph
	* named module members are special - we stop the walk when we hit such an object and its not part of our 'resolvability' criteria even if the object is unresolved at that point.
		* this is because any references that are through an actual module instead of through explicit
			forwards cannot affect our identity, only our compilation
	* everything else gets mapped to an explicit 'constant'
*


# core ideas:
# 1. it's typelike IFF it can't change during program execution
# 2. module members, class definitions, etc, don't change during program execution once set
# 3. an @Function / @Entrypoint should define an 'untyped' function to whatever degree possible
#    since the user isn't providing types
# 4. at the moment we cross Entrypoint boundaries we can look at a function's type graph and
#    determine how we want to handle it
# 5. we could have the idea of a 'StatefulClass' holding a class that references some state
#    that's independent of its type. This could get passed to its instances
# 6. a Function's default arguments, if stateful, should be part of its data not its type
# 7. if we have an anonymous module, and that module is defined in RF, then that module's identity
#    is it's "incoming state"


# this is just a regular TP function. nothing funny going on
@Function
def f():
	pass


# this should hold 'x' as a NamedModuleMember if this is defined inside of a module
# this is part of the type
@Function
def f():
	return x


# if the module is not named, then the module info is not part of the type.
# instead it's part of the Function's closure. 'x' should go through the closure
# and hit the dict indirectly.  If the function gets passed to a Class then we'll
# pull all of that apart and re-use it. If it just becomes a free function then
# when we interpret it, it's fine, and when we compile it we get a chance to look carefully
# at it and decide what to do.
__module__ = 'some random module we can't find
@Function
def f():
	return x


def makeF(x):
	@Function
	def f():




execution plan:
1. if a function's globals dict is not globally visible, then make it part of the _closure_
	* FunctionGlobal can point to the closure, just like the ClosureVariables
		* this is always considered 'resolved' in the sense that such an object is untyped and therefore fully resolved
	* need to allow the function to be recreated correctly given this case
2. allow forward function types to be instantiated if their closures are not forward. This is a forward function instance.
	* forward function instances can't be executed but they can be created. They are placeholder objects ready to be resolved
		just like forward types, or to be passed into a Class definition
3. allow forward function types to be resolved just like regular function types
	* forward function instances also participate in instance resolution





how to do this:
1. new graph needs a hashing methodology that's totally independent of MRTG
2. type internalization framework needs to use it



















D = Forward(lambda: X)

class C:
    MyD = D


class D(Class):
    MyC = C


How should we handle this case?

At some level, both C and D are 'forward defined' because 'C' has a forward reference to D and vice versa.

So, now we will have a new C and a new D, triggered at the moment we constructed 'D'.

Of course, if we allowed 'C' to escape then we have a problem



Of course, when we define C we wont' have

at the module level, we shouldn't be replacing 'C', we should be updating it?

how can we tell the difference between these two?

Should 'C' have been considered 'Forward Defined'?

